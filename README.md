# Logistic-regression-Customer-Churn
I took upon a project to tackle the problem of customer churn within a fictitious bank called Star Gaze Bank. The analysis aims to discover the underlying causes of churn, allowing for the development of strategies to retain customers more effectively. Through logistic regression analysis, my goal is to uncover the underlying relationships within the bank dataset. Python was used throughout this project

## Summary of solution deployment
To kickstart my analysis, I imported the libraries needed. I always add “%matplotlib inline” command to ensure that the plot generated by plt.plot() is displayed directly below the code cell. I also imported my file and displayed them on a pandas data frame. My data has 10,000 rows and 14 columns
Below is the breakdown of the data and what each column is. This data was obtained from Kaggle

- RowNumber: This column contains the index number for each row
- CustomerId: This is a unique identifier for each customer
- Surname: The Surname (last name) of the customer.
- CreditScore: The credit score of the customer, is the numerical rating of their creditworthiness. The higher the score, the higher the creditworthiness.
- Geography: The country or region where the customer is located.
- Gender: This the sex of the customer, which can be “Male” or “Female.”
- Age: The age of the customer.
- Tenure: The number of years the customer has had an account with the bank.
- Balance: The account balance of the customer.
- NumOfProducts: The number of bank products (e.g., accounts, loans, credit cards) that the customer has.
- HasCrCard: This is a binary variable that shows whether the customer has a credit card (1 for “Yes” and 0 for “No”).
- IsActiveMember: Also a binary variable indicating whether the customer is an active member (1 for “Yes” and 0 for “No”).
- EstimatedSalary: The estimated salary of the customer.
- Exited: This indicates whether the customer has churned (left the bank’s services) or not (1 for “Yes” and 0 for “No”)

## Data Cleaning

- Checking for and emoving null values
- Removing duplicates
- Checking for outliers
    These are  some important steps when preparing a dataset for analysis. The cleaner the data, the more accurate the analysis will be. I began by checking for null values and duplicates . There were none present. I also renamed relevant columns

## Exploratory Analysis
  You can’t start a data analysis process without first exploring your data to understand better what kind of information you have at hand and what can be done with it. I decided to create visuals to help me understand the distribution of my data and find outliers too. 
  
- What is the age distrubution
- Salary distribution by gender
- Gender distribution
- Churn distribution by gender
- Bank balance distribution

  After my exploratory data analysis (EDA) on the dataset, It was essential to construct a correlation matrix. This matrix sheds light on the interconnections between various variables in the dataset. It assists in the selection of appropriate dependent and independent variables, ensuring the model’s effectiveness.
 I was able to select the best variables for my analysis with the help of the correlation matrix. Age (0.29) and Balance (0.12) have the highest correlation to my Dependent variable “Churn”.

My goal now is to predict churn using Age and Balance

## Training and Testing the model
After importing machine learning libraries like scikit-learn, I trained my model with 70% of the data and 30% will be used for testing. After running the code for my model, my prediction accuracy was 80%. Not bad! Also, note it is important to always add a “Random_state” to your model to ensure it produces the same result regardless of where it is run.

## Model performance evaluation

Next up is to evaluate the performance of my model using different logistics performance metrics. I had first used the accuracy measure which showed the model had an 80% prediction accuracy. Next will be me creating a confusion matrix to evaluate how well my model predicts True positives and true negatives. I also created a table to show the actual vs. predicted. Additionally, it’s pertinent to generate a probability matrix, which serves as a measure of the machine learning model’s confidence in predicting a class as either 0 or 1. This matrix will aid in assessing the model’s certainty regarding its predictions of whether a customer will churn or not, providing insights into prediction accuracy.
In the first row showing “Predicted Probabilities for Positive Class (Churn),” the model displays a confidence level of 28% for class 1 and 71% for class 0.

## Summary &  Reccommendations

In my analysis of customer churn, I employed logistic regression to predict customer behavior and understand the factors influencing churn within my dataset of 10,000 customers. The model demonstrated promise with an accuracy of approximately 80.53%, indicating its potential to identify potential churners. However, upon closer examination of the confusion matrix, I noticed a challenge, the model had difficulty in correctly predicting customers in the positive class(1), i.e. those likely to churn.

This issue can be largely attributed to a significant class imbalance, where a substantial number of 7,963 non-churned customers vastly outnumber the 2,037 churned customers in my dataset. This imbalance can skew the model’s predictions, leading to a bias in favor of the majority class.

